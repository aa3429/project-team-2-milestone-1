DEXTR, or Deep Extreme Cut, obtains an object segmentation from its four extreme points: the left-most, right-most, top, and bottom pixels. The annotated extreme points are given as a guiding signal to the input of the network. To this end, we create a heatmap with activations in the regions of extreme points. We center a 2D Gaussian around each of the points, to create a single heatmap. The heatmap is concatenated with the RGB channels of the input image, to form a 4-channel input for the CNN. To focus on the object of interest, the input is cropped by the bounding box, which is a polygon, formed from the extreme point annotations. To include context on the resulting crop, we relax the tight bounding box by several pixels. After the pre-processing step that comes exclusively from the extreme clicks, the input consists of an RGB crop including an object, plus its extreme points.

The user provides the extreme clicks for an object, and the CNN produces the segmented masks. DEXTR can generate high-quality class-agnostic masks given only extreme points as input. The resulting masks can in turn be used to train other deep architectures for other tasks or datasets, that is, we use extreme points to annotate a new dataset with object segmentations.

ResNet-101 is chosen as backbone of the architecture. We remove the fully connected layers as well as the max pooling layers in the last two stages to preserve acceptable output resolution for dense prediction, and we introduce atrous convolutions in the last two stages to maintain the same receptive field. After the last ResNet-101 stage, we introduce a pyramid scene parsing module to aggregate global context to the final feature map. The output of the CNN is a probability map representing whether a pixel belongs to the object that we want to segment or not. The CNN is trained to minimize the standard cross entropy loss, which considers that different classes occur with different frequency in a dataset.

Usage for DEXTR:
i)	Class-agnostic Instance Segmentation: One application of DEXTR is class-agnostic instance segmentation. In this task, we click on the extreme points of an object in an image, and we obtain a mask prediction for it. The selected object can be of any class, as the method is class agnostic.
ii)	Annotation: The common annotation pipeline for segmentation can also be assisted by DEXTR. In this framework, instead of detailed polygon labels, the workload of the annotator is reduced to only providing the extreme points of an object, and DEXTR produces the desired segmentation.
iii)	Video Object Segmentation: DEXTR can also improve the pipeline of video object segmentation. We focus on the semi-supervised setting where methods use one or more masks as inputs to produce the segmentation of the whole video.

For Annotation: DEXTR can generate high-quality class-agnostic masks given only extreme points as input. The resulting masks can in turn be used to train other deep architectures for other tasks or datasets, that is, we use extreme points to annotate a new dataset with object segmentations. In our use case, we compare the results of a semantic segmentation algorithm trained on either the ground-truth masks or those generated by DEXTR (we combine all per-instance segmentations into a per-pixel semantic classification result).

CVat is an extensive and completely free open-source platform centered around 2D annotations for both images and video.
The UI is noticeably less intuitive at times. For instance, setting a filter only hides other annotations from the image being looked at. Unless you know this, there is no indication that you can also cycle through images that contain the filtered object using some key bindings. There is no visual feedback – such as a list of thumbnails – about the filter.

For semi-automatic annotation, DEXTR is provided. It works by selecting some extreme points of an object, after which the complete segmentation is derived.

DEXTR can also be used to obtain dense annotations to train supervised techniques. It is shows that very accurate annotations are obtained with respect to the ground truth, but more importantly, that algorithms trained on the annotations obtained by DEXTR algorithm perform as good as when trained from the ground-truth ones. If costs are added to obtain such annotations into the equation, then training using DEXTR is significantly more efficient than training from the ground truth for a given target quality.

One of the most common ways to perform weakly supervised segmentation is drawing a bounding box around the object of interest. However, to draw the corners of a bounding box, the user must click points outside the object, drag the box diagonally, and ad- just it several times to obtain a tight, accurate bounding box. This process is cognitively demanding, with increased error rates and labelling times.
Recently, Papadopoulos et al. have shown a much more efficient way of obtaining a bounding box using extreme clicks, spending on average 7.2 seconds instead of 34.5 seconds required for drawing a bounding box around an object. They show that extreme clicking leads to high quality bounding boxes that are on par with the ones obtained by traditional methods. These extreme points be- long to the top, bottom, left-most and right-most parts of the object. Extreme-clicking annotations provide more information than a bounding box; they contain four points that are on the boundary of the object, from which one can easily obtain the bounding-box. We use extreme points for object segmentation leveraging their two main outcomes: the points and their inferred bounding box.

Having the extreme points annotated allows for focusing on specific regions in an image, cropped by the limits specified by them. It is compared how beneficial it is to focus on the region of interest, rather than processing the entire image. To this end, we crop the region surrounded by the extreme points, relaxing it by 50 pixels for increased context and compare it against the full image case. This is because cropping eliminates the scale variation on the input.

Thus, DEXTR can also be used as an accurate and efficient mask annotation tool, reducing labeling costs by a factor of 10.
